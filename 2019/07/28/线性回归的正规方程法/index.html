<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><title>线性回归的正规方程法 | Irimsky's Blog</title><meta name="description" content="线性回归的正规方程法"><meta name="keywords" content="笔记,机器学习,线性回归,梯度下降,正规方程"><meta name="author" content="Irimsky"><meta name="copyright" content="Irimsky"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/bitbug_favicon.ico"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="canonical" href="/2019/07/28/线性回归的正规方程法/"><meta property="og:type" content="article"><meta property="og:title" content="线性回归的正规方程法"><meta property="og:url" content="/2019/07/28/线性回归的正规方程法/"><meta property="og:site_name" content="Irimsky's Blog"><meta property="og:description" content="线性回归的正规方程法"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/irimsky/CDN/ML2.png"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="prev" title="PTA-最大连续子数列和（4种方法）" href="/2019/07/29/PTA-最大连续子数列和（4种方法）/"><link rel="next" title="Python学习笔记(十)：迭代器和生成器" href="/2019/07/25/Python学习笔记-十-：迭代器和生成器/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  highlight_copy: 'true',
  highlight_lang: 'true',
  highlight_shrink: 'false',
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    title: '添加书签',
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  copyright: undefined,
  copy_copyright_js: false
  
}</script></head><body><div id="header"> <div id="page-header"><span class="pull-left" id="blog_name"><a class="blog_title" id="site-name" href="/">Irimsky's Blog</a></span><i class="fa fa-bars fa-fw toggle-menu pull-right close" aria-hidden="true"></i><span class="pull-right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-list"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-user"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-heart" aria-hidden="true"></i><span> List</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> Music</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> Movie</span></a></li></ul></div><script>document.body.addEventListener('touchstart', function(){ });</script></div></span><span class="pull-right" id="search_button"><a class="site-page social-icon search"><i class="fa fa-search fa-fw"></i><span> 搜索</span></a></span></div></div><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="lozad avatar_img" src="https://s2.ax1x.com/2019/11/02/KLL09s.jpg" onerror="onerror=null;src='/img/friend_404.gif'"></div><div class="mobile_post_data"><div class="mobile_data_item is_center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">23</div></a></div></div><div class="mobile_data_item is_center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">15</div></a></div></div><div class="mobile_data_item is_center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">10</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-list"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-user"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-heart" aria-hidden="true"></i><span> List</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> Music</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> Movie</span></a></li></ul></div><script>document.body.addEventListener('touchstart', function(){ });</script></div></div><div id="mobile-sidebar-toc"><div class="toc_mobile_headline">目录</div><ol class="toc_mobile_items"><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#正规方程"><span class="toc_mobile_items-text">正规方程</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#与梯度下降比较"><span class="toc_mobile_items-text">与梯度下降比较</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#矩阵不可逆时的情况"><span class="toc_mobile_items-text">矩阵不可逆时的情况</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#附：正则方程推导过程"><span class="toc_mobile_items-text">附：正则方程推导过程</span></a></li></ol></div></div><div id="body-wrap"><div id="web_bg"></div><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true">     </i><div class="auto_open" id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#正规方程"><span class="toc-text">正规方程</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#与梯度下降比较"><span class="toc-text">与梯度下降比较</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#矩阵不可逆时的情况"><span class="toc-text">矩阵不可逆时的情况</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#附：正则方程推导过程"><span class="toc-text">附：正则方程推导过程</span></a></li></ol></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://cdn.jsdelivr.net/gh/irimsky/CDN/ML2.png)"><div id="post-info"><div id="post-title"><div class="posttitle">线性回归的正规方程法</div></div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 发表于 2019-07-28<span class="post-meta__separator">|</span><i class="fa fa-history" aria-hidden="true"></i> 更新于 2019-11-03</time><span class="post-meta__separator mobile_hidden">|</span><span class="mobile_hidden"><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/机器学习/">机器学习</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/机器学习/吴恩达《机器学习》/">吴恩达《机器学习》</a></span><div class="post-meta-wordcount"><span>阅读量: </span><span id="busuanzi_value_page_pv"></span></div></div></div></div><div class="layout layout_post" id="content-inner">   <article id="post"><div class="article-container" id="post-content"><h1 id="正规方程"><a href="#正规方程" class="headerlink" title="正规方程"></a>正规方程</h1><hr>
<p>正规方程是通过求解下面的方程来找出使得代价函数最小的参数的： $\frac{\partial}{\partial \theta_j} J(\theta_i) = 0$</p>
<p>假设我们的训练集特征矩阵为 $X$（包含了 𝑥0 = 1）并且我们的训练集结果为向量 $y$，则利<br>用正规方程解出向量 </p>
<script type="math/tex; mode=display">\theta = (X^TX)^{-1}X^Ty</script><a id="more"></a>
<p>比如如下的数据：<br><img alt="在这里插入图片描述" data-src="https://s2.ax1x.com/2019/08/16/mmYiqI.png" class="lozad"></p>
<script type="math/tex; mode=display">X =  \begin{bmatrix}
  1 & 2104 & 5 & 1 & 45\\
  1 & 1416 & 3 & 2 & 40\\
  1 & 1534 & 3 & 2 & 30 \\
  1 & 852 & 2 & 1 & 36 & \\
  \end{bmatrix}</script><script type="math/tex; mode=display">y = \begin{bmatrix}
  460\\
  232\\
  315\\
  178\\
  \end{bmatrix}</script><p><br><br><br><b>正规方程的Python实现：</b><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normalEqn</span><span class="params">(X, y)</span>:</span>    </span><br><span class="line">	theta = np.linalg.inv(X.T@X)@X.T@y <span class="comment">#X.T@X等价于 X.T.dot(X) </span></span><br><span class="line">	<span class="keyword">return</span> theta</span><br></pre></td></tr></table></figure></p>
<p><br><br></p>
<h1 id="与梯度下降比较"><a href="#与梯度下降比较" class="headerlink" title="与梯度下降比较"></a>与梯度下降比较</h1><hr>
<div class="table-container">
<table>
<thead>
<tr>
<th>梯度下降</th>
<th>正规方程</th>
</tr>
</thead>
<tbody>
<tr>
<td>需要选择学习率𝛼</td>
<td>不需要</td>
</tr>
<tr>
<td>需要多次迭代</td>
<td>一次运算得出</td>
</tr>
<tr>
<td>当特征数量𝑛大时也能较好适用</td>
<td>需要计算$(X^TX)^-1$。如果特征数量𝑛较大则 运算代价大，<br>因为矩阵逆的计算时间复杂度 为𝑂(𝑛3) </td>
</tr>
<tr>
<td>适用于各种类型的模型</td>
<td>只适用于线性模型，不适合逻辑回归模型等其他模型 </td>
</tr>
</tbody>
</table>
</div>
<p><br></p>
<h1 id="矩阵不可逆时的情况"><a href="#矩阵不可逆时的情况" class="headerlink" title="矩阵不可逆时的情况"></a>矩阵不可逆时的情况</h1><hr>
<p>$(X^TX)$会出现不可逆的情况。<br>原因可能有：</p>
<ol>
<li><b>有多余的特征变量成了线性相关关系</b><br>比如一个特征是厘米单位的长度，而另一个特征是毫米单位的长度，两列数据在自乘之后成了100倍的线性关系。<br>这时就需要把多余的特征量删除。</li>
<li><b>有太多的特征量（m &lt;&lt; n）</b> <em>有时还会导致‘过拟合(overfit)’的现象</em><br>比如m = 10, n = 100时的情况，则需要在10个训练样本中找出101个参数，这是一种比较复杂且容易出问题的任务。<br>解决方法有：<br>①删除一些特征量<br>②<font color="blue"><b>正则化</b></font><br><br></li>
</ol>
<h1 id="附：正则方程推导过程"><a href="#附：正则方程推导过程" class="headerlink" title="附：正则方程推导过程"></a>附：正则方程推导过程</h1><hr>
<p><br><br></p>
<script type="math/tex; mode=display">J(\theta_0,\theta_1,\dots,\theta_n) = \frac {1}{2m}\sum_{i=1}^{m}\ (h_\theta(x^{(i)})  - y^{(i)})^2</script><p>转化为矩阵表示则有：</p>
<script type="math/tex; mode=display">J(\theta) = \frac{1}{2} (X\theta-y)^T(X\theta-y)</script><script type="math/tex; mode=display">\ \ \ \ \ \ = \frac{1}{2} (\theta^TX^T-y^T)(X\theta-y)</script><script type="math/tex; mode=display">\ \ \ \ \ \ = \frac{1}{2} (\theta^TX^TX\theta-\theta^TX^Ty-y^TX\theta + y^Ty)</script><p><br><br><br>接下来对$\theta$求偏导。要用到几个矩阵求导法则：<br>$\frac{dAB}{dB} = A^T$、$\frac{dA^TXA}{dX}=2AX$</p>
<p>所以有：</p>
<script type="math/tex; mode=display">\frac{\partial}{\partial \theta} J(\theta) = \frac{1}{2}(2X^TX\theta - X^Ty -(y^TX)^T+0)</script><script type="math/tex; mode=display">= (X^TX\theta - X^Ty)</script><p>令其=0，可得：</p>
<script type="math/tex; mode=display">\theta = (X^TX)^{-1}X^Ty</script></div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Irimsky</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="/2019/07/28/线性回归的正规方程法/">/2019/07/28/线性回归的正规方程法/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href>Irimsky's Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/笔记/">笔记    </a><a class="post-meta__tags" href="/tags/机器学习/">机器学习    </a><a class="post-meta__tags" href="/tags/线性回归/">线性回归    </a><a class="post-meta__tags" href="/tags/梯度下降/">梯度下降    </a><a class="post-meta__tags" href="/tags/正规方程/">正规方程    </a></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/irimsky/CDN/ML2.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script></div></div><nav class="pagination_post" id="pagination"><div class="prev-post pull-left"><a href="/2019/07/29/PTA-最大连续子数列和（4种方法）/"><img class="prev_cover lozad" data-src="https://s2.ax1x.com/2019/11/02/KOpdl4.png" onerror="onerror=null;src='https://s2.ax1x.com/2019/11/02/KOCiVI.jpg'"><div class="label">上一篇</div><div class="prev_info"><span>PTA-最大连续子数列和（4种方法）</span></div></a></div><div class="next-post pull-right"><a href="/2019/07/25/Python学习笔记-十-：迭代器和生成器/"><img class="next_cover lozad" data-src="https://cdn.jsdelivr.net/gh/irimsky/CDN/Pycov.png" onerror="onerror=null;src='https://s2.ax1x.com/2019/11/02/KOCiVI.jpg'"><div class="label">下一篇</div><div class="next_info"><span>Python学习笔记(十)：迭代器和生成器</span></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2019/07/24/多元梯度下降/" title="多元梯度下降"><img class="relatedPosts_cover lozad" data-src="https://cdn.jsdelivr.net/gh/irimsky/CDN/ML2.png"><div class="relatedPosts_title">多元梯度下降</div></a></div><div class="relatedPosts_item"><a href="/2019/08/24/逻辑回归/" title="逻辑回归"><img class="relatedPosts_cover lozad" data-src="https://cdn.jsdelivr.net/gh/irimsky/CDN/ML2.png"><div class="relatedPosts_title">逻辑回归</div></a></div><div class="relatedPosts_item"><a href="/2019/07/16/简单线性回归和梯度下降/" title="简单线性回归和梯度下降"><img class="relatedPosts_cover lozad" data-src="https://cdn.jsdelivr.net/gh/irimsky/CDN/ML2.png"><div class="relatedPosts_title">简单线性回归和梯度下降</div></a></div><div class="relatedPosts_item"><a href="/2019/07/12/Python学习笔记-四/" title="Python学习笔记(四)：if语句"><img class="relatedPosts_cover lozad" data-src="https://cdn.jsdelivr.net/gh/irimsky/CDN/Pycov.png"><div class="relatedPosts_title">Python学习笔记(四)：if语句</div></a></div><div class="relatedPosts_item"><a href="/2019/07/13/Python学习笔记-六/" title="Python学习笔记(六)：输入与while循环"><img class="relatedPosts_cover lozad" data-src="https://cdn.jsdelivr.net/gh/irimsky/CDN/Pycov.png"><div class="relatedPosts_title">Python学习笔记(六)：输入与while循环</div></a></div><div class="relatedPosts_item"><a href="/2019/07/13/Python学习笔记-五/" title="Python学习笔记(五):字典"><img class="relatedPosts_cover lozad" data-src="https://cdn.jsdelivr.net/gh/irimsky/CDN/Pycov.png"><div class="relatedPosts_title">Python学习笔记(五):字典</div></a></div></div><div class="clear_both"></div></div><hr><div id="post-comment"><div class="comment_headling"><i class="fa fa-comments fa-fw" aria-hidden="true"></i><span> 评论</span></div><div class="vcomment" id="vcomment"></div><script src="https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js"></script><script>var notify = true == true ? true : false;
var verify = true == true ? true : false;
var GUEST_INFO = ['nick','mail','link'];
var guest_info = 'nick,mail,link'.split(',').filter(function(item){
  return GUEST_INFO.indexOf(item) > -1
});
guest_info = guest_info.length == 0 ? GUEST_INFO :guest_info;

window.valine = new Valine({
  el:'#vcomment',
  notify:notify,
  verify:verify,
  appId:'qdBhaxYGDv9tgYgY6RD4CwWK-gzGzoHsz',
  appKey:'wmEoQT38qhEH88DHMMPiFNEJ',
  placeholder:'说点什么吧',
  avatar:'mp',
  guest_info:guest_info,
  pageSize:'10',
  lang:'zh-cn',
  recordIP: true
});</script></div></div></div><footer><div id="footer"><div class="copyright">&copy;2018 - 2019 By Irimsky</div><div class="framework-info"><span>驱动 </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly"><span>Butterfly</span></a></div><div class="footer_custom_text">Welcome to my bolg</div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换">繁</a><i class="nightshift fa fa-moon-o" id="nightshift" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><a id="to_comment" href="#post-comment" title="直达评论"><i class="scroll_to_comment fa fa-comments">  </i></a><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/js-cookie@2/src/js.cookie.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script async src="/js/search/local-search.js"></script><script src="/js/nightshift.js"></script><script src="/js/tw_cn.js"></script><script>translateInitilization()

</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@1.2.2/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script><script>const observer = lozad(); // lazy loads elements with default selector as '.lozad'
observer.observe();
</script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>