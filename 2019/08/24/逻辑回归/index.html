<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><title>逻辑回归 | Irimsky's Blog</title><meta name="description" content="逻辑回归"><meta name="keywords" content="笔记,机器学习,线性回归,梯度下降"><meta name="author" content="Irimsky"><meta name="copyright" content="Irimsky"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/bitbug_favicon.ico"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="canonical" href="/2019/08/24/逻辑回归/"><meta property="og:type" content="article"><meta property="og:title" content="逻辑回归"><meta property="og:url" content="/2019/08/24/逻辑回归/"><meta property="og:site_name" content="Irimsky's Blog"><meta property="og:description" content="逻辑回归"><meta property="og:image" content="https://s2.ax1x.com/2019/11/02/KOCiVI.jpg"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="prev" title="链式前向星【存图模板】" href="/2019/10/12/链式前向星【存图模板】/"><link rel="next" title="最长递增子序列（LIS）的三种算法" href="/2019/08/16/最长递增子序列（LIS）的三种算法/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  highlight_copy: 'true',
  highlight_lang: 'true',
  highlight_shrink: 'false',
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    title: '添加书签',
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  copyright: undefined,
  copy_copyright_js: false
  
}</script></head><body><div id="header"> <div id="page-header"><span class="pull-left" id="blog_name"><a class="blog_title" id="site-name" href="/">Irimsky's Blog</a></span><i class="fa fa-bars fa-fw toggle-menu pull-right close" aria-hidden="true"></i><span class="pull-right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-list"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-user"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-heart" aria-hidden="true"></i><span> List</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> Music</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> Movie</span></a></li></ul></div><script>document.body.addEventListener('touchstart', function(){ });</script></div></span><span class="pull-right" id="search_button"><a class="site-page social-icon search"><i class="fa fa-search fa-fw"></i><span> 搜索</span></a></span></div></div><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="lozad avatar_img" src="https://s2.ax1x.com/2019/11/02/KLL09s.jpg" onerror="onerror=null;src='/img/friend_404.gif'"></div><div class="mobile_post_data"><div class="mobile_data_item is_center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">21</div></a></div></div><div class="mobile_data_item is_center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">14</div></a></div></div><div class="mobile_data_item is_center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">7</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-list"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-user"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-heart" aria-hidden="true"></i><span> List</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> Music</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> Movie</span></a></li></ul></div><script>document.body.addEventListener('touchstart', function(){ });</script></div></div><div id="mobile-sidebar-toc"><div class="toc_mobile_headline">目录</div><ol class="toc_mobile_items"><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#简单二元分类"><span class="toc_mobile_items-text">简单二元分类</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#逻辑回归"><span class="toc_mobile_items-text">逻辑回归</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#假设模型"><span class="toc_mobile_items-text">假设模型</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#决策边界"><span class="toc_mobile_items-text">决策边界</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#代价函数"><span class="toc_mobile_items-text">代价函数</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#多类别分类：一对多"><span class="toc_mobile_items-text">多类别分类：一对多</span></a></li></ol></div></div><div id="body-wrap"><div id="web_bg"></div><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true">     </i><div class="auto_open" id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#简单二元分类"><span class="toc-text">简单二元分类</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#逻辑回归"><span class="toc-text">逻辑回归</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#假设模型"><span class="toc-text">假设模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#决策边界"><span class="toc-text">决策边界</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#代价函数"><span class="toc-text">代价函数</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#多类别分类：一对多"><span class="toc-text">多类别分类：一对多</span></a></li></ol></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://s2.ax1x.com/2019/11/02/KOCiVI.jpg)"><div id="post-info"><div id="post-title"><div class="posttitle">逻辑回归</div></div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 发表于 2019-08-24<span class="post-meta__separator">|</span><i class="fa fa-history" aria-hidden="true"></i> 更新于 2019-10-09</time><span class="post-meta__separator mobile_hidden">|</span><span class="mobile_hidden"><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/机器学习/">机器学习</a></span><div class="post-meta-wordcount"><span>阅读量: </span><span id="busuanzi_value_page_pv"></span></div></div></div></div><div class="layout layout_post" id="content-inner">   <article id="post"><div class="article-container" id="post-content"><p>在<b>分类问题</b>中，我们尝试预测的是结果是否属于某一个类（例如正确或错误），其往往是一个离散的值。比如：判断一封电子邮件是否是垃圾邮件；判断一次金融交易是否是欺诈。</p>
<p> <b>逻辑回归</b>算法，是用于分类问题的最广泛的学习算法。<br> <a id="more"></a><br> <br><br> <br></p>
<h1 id="简单二元分类"><a href="#简单二元分类" class="headerlink" title="简单二元分类"></a>简单二元分类</h1><hr>
<p> 我们将<b>因变量(dependent variable)</b>可能属于的两个类分别称为<b>负向类（negative class）</b>和<b>正向类（positive class）</b>，则因变量 y∈{0,1} ，其中 0 表示负向类，1 表示正向类。 </p>
<p> 而我们将用逻辑回归算法使得假设函数 $h_\theta(x)$ 的输出范围∈[0,1]，表示$P(y=1|x; \theta)$，即<b>“因变量 y=1 的概率”。</b><br><br></p>
<p><font size="2"><em>注：虽然“逻辑回归”的名字中带有“回归”二字，但其仍属于分类算法。</em></font><br><br><br><br></p>
<h1 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h1><hr>
<h2 id="假设模型"><a href="#假设模型" class="headerlink" title="假设模型"></a>假设模型</h2><p>如果对如图的数据集进行线性回归的话，会得到一条直线。其结果并不能用作分类（值域不在0-1内）<br><img alt="在这里插入图片描述" data-src="https://s2.ax1x.com/2019/08/24/m6gFlq.png" class="lozad"><br><br><br>而<b>逻辑回归</b>的预测模型为：</p>
<script type="math/tex; mode=display">h_\theta(x) = g(\theta^TX)</script><p>其中 </p>
<script type="math/tex; mode=display">g(z) = \frac{1}{1+e^{-z}}</script><p>该函数图像如图所示：<img alt="在这里插入图片描述" data-src="https://s2.ax1x.com/2019/08/24/m6g9Yj.png" class="lozad"><br>如前所言，$h_\theta(x)$ 的作用是：对于给定的输入变量，根据选择的参数计算输出变量=1的<b>可能性</b>，即$P(y=1|x; \theta)$<br>例如，如果对于给定的𝑥，通过已经确定的参数计算得出$h_\theta(x)$ = 0.7，则表示有70%的几率𝑦为正向类，相应地𝑦为负向类的几率为 30%<br><br></p>
<h2 id="决策边界"><a href="#决策边界" class="headerlink" title="决策边界"></a>决策边界</h2><p>若以0.5作为区分正向类与负向类的阈值，则可以发现：对于函数$g(z) = \frac{1}{1+e^{-z}}$，在$z<0$时,$g(z)$< $0.5$ ；而$z>0$时，$g(z)$ &gt; $0.5$</0$时,$g(z)$<></p>
<p>即</p>
<script type="math/tex; mode=display">\theta^Tx>0 时，y=1</script><script type="math/tex; mode=display">\theta^Tx<0 时，y=0</script><p> <br><br><img alt="在这里插入图片描述" data-src="https://s2.ax1x.com/2019/08/24/m6gCfs.png" class="lozad"><br>假设有如图的数据集，且经过线性回归后得到 $\theta^TX = -3 + x_1 + x_2$</p>
<p>则在图上画出$x_1+x_2=3$的图像。不难看出，这便是数据集的<b>分界线</b>，被称为<b>决策边界(decision boundary)</b>。将预测为 1 的区域（ $-3 + x_1 + x_2&gt;0$）和预测为 0 的区域($-3 + x_1 + x_2&lt;0$)分隔开。</p>
<ul>
<li>注：决策边界是<b>假设模型</b>的属性，而不是数据集的属性。决策边界取决于模型的选择。</li>
</ul>
<p>我们可以用非常复杂的模型来适应非常复杂形状的判定边界。<br>如图，假设已知$h_\theta(x)=-1 +x_1^2+x_2^2$，即正好是一个以原点为圆心，1为半径的圆。<br><img alt="在这里插入图片描述" data-src="https://s2.ax1x.com/2019/08/24/m6gk60.png" class="lozad"></p>
<p><br><br></p>
<h2 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a>代价函数</h2><p>若将逻辑回归的模型代入线性回归的代价函数（误差平方和，即方差），得到的代价函数将会是一个<a href="https://blog.csdn.net/qq_38009970/article/details/87787488" target="_blank" rel="noopener">非凸函数</a><b>(non-convexfunction)</b>，无法进行梯度下降<br><img alt="在这里插入图片描述" data-src="https://s2.ax1x.com/2019/08/24/m6gipn.png" class="lozad"><br>对于线性回归，其代价函数可以表示为：（这是<b>单训练样本的代价函数</b>表达形式）</p>
<script type="math/tex; mode=display">Cost(h_\theta(x),\ y)=\frac{1}{2}(h_\theta(x)-y)^2</script><script type="math/tex; mode=display">J(\theta)=\frac{1}{m}\sum^{m}_{i=1}Cost(h_\theta(x^{(i)}),\ y^{(i)})</script><p>而逻辑回归的代价函数较为不同。</p>
<script type="math/tex; mode=display">Cost(h_\theta(x),\ y)=\begin{cases}
-\log(h_\theta(x)) & y = 1 \\
-(\log(1-h_\theta(x))) & y = 0
\end{cases}</script><p>这样构建的$Cost(h_\theta(x),y)$函数的特点是：<b>当实际的 𝑦 = 1 且$h_\theta(x)$也为 1 时误差为 0，当 𝑦 = 1 但$h_\theta(x)$不为 1 时误差随着$h_\theta(x)$变小而变大；当实际的 𝑦 = 0 且ℎ𝜃(𝑥)也为 0 时代价为 0，当𝑦 = 0 但$h_\theta(x)$不为 0 时误差随着 $h_\theta(x)$的变大而变大。</b><br><img alt="在这里插入图片描述" data-src="https://s2.ax1x.com/2019/08/24/m6gAXV.png" class="lozad"></p>
<p>为了对其进行梯度下降，将其化简为：</p>
<script type="math/tex; mode=display">Cost(h_\theta(x),\ y)=-y\log(h_\theta(x))-(1-y) \log(1-h_\theta(x))</script><script type="math/tex; mode=display">J(\theta) = -\frac{1}{m}\sum^{m}_{i=1}[y\log(h_\theta(x))+(1-y) \log(1-h_\theta(x)]</script><p>接着对其使用梯度下降，需要对其求偏导。<br>求导过程：<br><img alt="在这里插入图片描述" data-src="https://s2.ax1x.com/2019/08/24/m6gVmT.png" class="lozad"></p>
<ul>
<li>注：可以发现最后的结果和线性回归的代价函数求导结果一样，但其<b>性质完全不同</b>，因为$h_\theta(x)$的性质不一样。</li>
</ul>
<p>最终得到梯度下降算法：</p>
<script type="math/tex; mode=display">
\begin {aligned}
Re&peat \{ \\
&\theta_j = \theta_j - \alpha\frac{1}{m}\sum^{m}_{i=1}[h_\theta(x^{(i)})-y^{(i)}]x_j^{(i)}\\
&\}
\end {aligned}</script><p><br><br><br></p>
<h1 id="多类别分类：一对多"><a href="#多类别分类：一对多" class="headerlink" title="多类别分类：一对多"></a>多类别分类：<font size="5">一对多</font></h1><hr>
<p>现实中有很多的多类别分类问题。比如判断天气是阴晴雨雪，或者判断邮件由来是家庭、公司或者陌生人。<br>用不同的编号表示不同的类别（比如 晴是1，阴是2，雨是3，雪是4）</p>
<p>多类别分类的数据集可能会像这样：</p>
<p><img alt="在这里插入图片描述" data-src="https://s2.ax1x.com/2019/08/24/m6gZ0U.png" class="lozad"><br>解决这种问题可以用一种叫<b>“一对多”（one-vs-all）</b>的算法，是由二元分类推广而来的，有时也叫<b>“一对余（one-vs-rest）”</b></p>
<ul>
<li>我们先从用三角形代表的类别 1 开始，实际上我们可以创建一个，新的”伪”训练集，类<br>型 2 和类型 3 定为同一种负类，类型 1 设定为正类，我们创建一个新的训练集。<br><img alt="在这里插入图片描述" data-src="https://s2.ax1x.com/2019/08/24/m6ge7F.png" class="lozad"><br>这样可以得到一个二元分类模型，记为$h_\theta^{(1)}(x)$<br><br></li>
<li>以此类推，得到一系列模型。其中$h_\theta^{(i)}(x)$代表的含义为：<b>y = i 的概率</b>，即$P(y=i|x; \theta)$<br><img alt="在这里插入图片描述" data-src="https://s2.ax1x.com/2019/08/24/m6gnk4.png" class="lozad"></li>
<li>当我们输入一个新的x时，可以得到3个结果，然后我们选择最大的一个，即 $\max h_\theta^{(i)}(x)$，$i$ 即为预测结果。</li>
</ul>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Irimsky</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="/2019/08/24/逻辑回归/">/2019/08/24/逻辑回归/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href>Irimsky's Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/笔记/">笔记    </a><a class="post-meta__tags" href="/tags/机器学习/">机器学习    </a><a class="post-meta__tags" href="/tags/线性回归/">线性回归    </a><a class="post-meta__tags" href="/tags/梯度下降/">梯度下降    </a></div><div class="post_share"><div class="social-share" data-image="https://s2.ax1x.com/2019/11/02/KOCiVI.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script></div></div><nav class="pagination_post" id="pagination"><div class="prev-post pull-left"><a href="/2019/10/12/链式前向星【存图模板】/"><img class="prev_cover lozad" data-src="https://s2.ax1x.com/2019/11/02/KOpdl4.png" onerror="onerror=null;src='https://s2.ax1x.com/2019/11/02/KOCiVI.jpg'"><div class="label">上一篇</div><div class="prev_info"><span>链式前向星【存图模板】</span></div></a></div><div class="next-post pull-right"><a href="/2019/08/16/最长递增子序列（LIS）的三种算法/"><img class="next_cover lozad" data-src="https://s2.ax1x.com/2019/11/02/KLxxn1.jpg" onerror="onerror=null;src='https://s2.ax1x.com/2019/11/02/KOCiVI.jpg'"><div class="label">下一篇</div><div class="next_info"><span>最长递增子序列（LIS）的三种算法</span></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2019/07/24/多元梯度下降/" title="多元梯度下降"><img class="relatedPosts_cover lozad" data-src="https://s2.ax1x.com/2019/11/02/KOCiVI.jpg"><div class="relatedPosts_title">多元梯度下降</div></a></div><div class="relatedPosts_item"><a href="/2019/07/28/线性回归的正规方程法/" title="线性回归的正规方程法"><img class="relatedPosts_cover lozad" data-src="https://s2.ax1x.com/2019/11/02/KOCiVI.jpg"><div class="relatedPosts_title">线性回归的正规方程法</div></a></div><div class="relatedPosts_item"><a href="/2019/07/16/简单线性回归和梯度下降/" title="简单线性回归和梯度下降"><img class="relatedPosts_cover lozad" data-src="https://s2.ax1x.com/2019/11/02/KOCiVI.jpg"><div class="relatedPosts_title">简单线性回归和梯度下降</div></a></div></div><div class="clear_both"></div></div><hr><div id="post-comment"><div class="comment_headling"><i class="fa fa-comments fa-fw" aria-hidden="true"></i><span> 评论</span></div><div class="vcomment" id="vcomment"></div><script src="https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js"></script><script>var notify = false == true ? true : false;
var verify = true == true ? true : false;
var GUEST_INFO = ['nick','mail','link'];
var guest_info = 'nick,mail,link'.split(',').filter(function(item){
  return GUEST_INFO.indexOf(item) > -1
});
guest_info = guest_info.length == 0 ? GUEST_INFO :guest_info;

window.valine = new Valine({
  el:'#vcomment',
  notify:notify,
  verify:verify,
  appId:'qdBhaxYGDv9tgYgY6RD4CwWK-gzGzoHsz',
  appKey:'wmEoQT38qhEH88DHMMPiFNEJ',
  placeholder:'说点什么吧',
  avatar:'monsterid',
  guest_info:guest_info,
  pageSize:'10',
  lang:'zh-cn',
  recordIP: true
});</script></div></div></div><footer><div id="footer"><div class="copyright">&copy;2018 - 2019 By Irimsky</div><div class="framework-info"><span>驱动 </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly"><span>Butterfly</span></a></div><div class="footer_custom_text">Welcome to my bolg</div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换">繁</a><i class="nightshift fa fa-moon-o" id="nightshift" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><a id="to_comment" href="#post-comment" title="直达评论"><i class="scroll_to_comment fa fa-comments">  </i></a><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/js-cookie@2/src/js.cookie.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script async src="/js/search/local-search.js"></script><script src="/js/nightshift.js"></script><script src="/js/tw_cn.js"></script><script>translateInitilization()

</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@1.2.2/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script><script>const observer = lozad(); // lazy loads elements with default selector as '.lozad'
observer.observe();
</script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>